# Loan Approval Prediction Analysis Report

## Executive Summary
This report analyzes a loan approval dataset using machine learning techniques to predict loan status (approved or rejected). The dataset contains features such as number of dependents, education level, employment status, income, loan amount, loan term, CIBIL score, and asset values. Preprocessing involved handling potential missing values by replacing zeros with NaNs and visualizing them. Multiple classification models were trained and evaluated, with the Decision Tree Classifier achieving the highest accuracy of 97.5%. The model was saved for future deployment. Recommendations include using the Decision Tree model for production and further feature engineering to enhance interpretability.

## Introduction
### Background
Loan approval prediction is a critical task in financial services to assess credit risk and automate decision-making. This analysis uses a refined dataset to predict loans as approved (0) or rejected (1) based on applicant attributes.

### Objectives
- Load and preprocess the dataset.
- Perform exploratory data analysis (EDA) to identify patterns and missing values.
- Train and evaluate multiple machine learning models.
- Compare model performance and select the best one.
- Save the optimal model for deployment.

### Dataset Overview
- **Source**: 'refined_loan_approval_dataset.csv' (loaded via pandas).
- **Shape**: 4269 rows Ã— 13 columns (initially), reduced to 12 columns after dropping 'loan_id'.
- **Features**:
  - Numerical: no_of_dependents, income_annum, loan_amount, loan_term, cibil_score, residential_assets_value, commercial_assets_value, luxury_assets_value, bank_asset_value.
  - Categorical (binary): education (0/1), self_employed (0/1).
- **Target**: loan_status (binary: 0 for approved, 1 for rejected).
- **Sample Data** (first few rows for illustration):

| loan_id | no_of_dependents | education | self_employed | income_annum | loan_amount | loan_term | cibil_score | residential_assets_value | commercial_assets_value | luxury_assets_value | bank_asset_value | loan_status |
|---------|------------------|-----------|---------------|--------------|-------------|-----------|-------------|--------------------------|--------------------------|---------------------|------------------|-------------|
| 1       | 2                | 0         | 0             | 9600000      | 29900000    | 12        | 778         | 2400000                  | 17600000                 | 22700000            | 8000000          | 0           |
| 2       | 0                | 1         | 1             | 4100000      | 12200000    | 8         | 417         | 2700000                  | 2200000                  | 8800000             | 3300000          | 1           |
| 3       | 3                | 0         | 0             | 9100000      | 29700000    | 20        | 506         | 7100000                  | 4500000                  | 33300000            | 12800000         | 1           |

The dataset appears clean but requires handling of zero values, which may represent missing or invalid entries.

## Methodology
### Tools and Libraries
- Python 3.12.3 environment.
- Libraries: numpy, pandas (data manipulation), matplotlib/seaborn (visualization), scikit-learn (modeling and evaluation).
- Models Evaluated: Linear Discriminant Analysis (LDA), Logistic Regression, Decision Tree, Support Vector Classifier (SVC), K-Nearest Neighbors (KNN), Gaussian Naive Bayes (GNB).

### Data Preprocessing
1. **Loading Data**: Read CSV into a pandas DataFrame.
2. **Feature Selection**: Dropped 'loan_id' as it is non-predictive.
3. **Handling Zeros as Missing Values**: Replaced all 0s with NaN across all columns (including target), assuming 0s indicate missing/invalid data.
4. **Column Cleanup**: Stripped whitespace from column names for consistency.
5. **Train-Test Split**: Assumed 80-20 split (not explicitly shown in code but inferred from model evaluation on X_test/y_test of size 854 samples).
6. **No Scaling/Imputation Shown**: Models were trained directly; potential scaling might be needed for distance-based models like KNN/SVC.

Post-preprocessing DataFrame (with NaNs):
- Many columns now have NaNs where 0s were present, especially in binary features like 'education' and 'self_employed'.

### Exploratory Data Analysis (EDA)
- **Missing Values Visualization**: A heatmap was generated using seaborn to show NaN distribution.
  - Key Insight: High NaNs in 'education' (where 0 was replaced), 'self_employed', 'no_of_dependents' (for 0 dependents), and 'loan_status' (for approved loans).
  - Heatmap Interpretation: Yellow bands indicate NaNs; the dataset has structured missingness due to the replacement rule, suggesting zeros were placeholders in categorical/binary fields.

No further EDA (e.g., correlations, distributions) was performed in the notebook.

### Model Training and Evaluation
- **Assumptions**: Features (X) exclude target; target (y) is 'loan_status'. Train-test split was performed (test size ~20%, n=854).
- **Metrics**: Accuracy, Confusion Matrix, Classification Report (Precision, Recall, F1-Score).
- **Models Trained**:
  1. Linear Discriminant Analysis (LDA).
  2. Logistic Regression (max_iter=1000).
  3. Decision Tree Classifier (random_state=42).
  4. Support Vector Classifier (SVC, random_state=42).
  5. K-Nearest Neighbors (KNN, n_neighbors=5).
  6. Gaussian Naive Bayes (GNB).

## Results
### Model Performance Comparison
The models were evaluated on the test set (n=854 samples: 536 approved, 318 rejected).

| Model                  | Accuracy | Precision (Class 0) | Recall (Class 0) | F1-Score (Class 0) | Precision (Class 1) | Recall (Class 1) | F1-Score (Class 1) |
|------------------------|----------|---------------------|------------------|--------------------|---------------------|------------------|--------------------|
| LDA                   | 91.6%   | 0.96                | 0.90             | 0.93               | 0.85                | 0.94             | 0.89               |
| Logistic Regression   | 82.2%   | 0.82                | 0.92             | 0.87               | 0.83                | 0.66             | 0.73               |
| Decision Tree         | 97.5%   | 0.98                | 0.98             | 0.98               | 0.97                | 0.97             | 0.97               |
| SVC                   | 62.8%   | 0.63                | 1.00             | 0.77               | 0.00                | 0.00             | 0.00               |
| KNN (n=5)             | 57.7%   | 0.64                | 0.75             | 0.69               | 0.41                | 0.29             | 0.34               |
| Gaussian Naive Bayes  | 76.9%   | 0.74                | 0.98             | 0.84               | 0.92                | 0.42             | 0.57               |

### Confusion Matrices
- **LDA**:
  ```
  [[483  53]
   [ 19 299]]
  ```
- **Logistic Regression**:
  ```
  [[492  44]
   [108 210]]
  ```
- **Decision Tree**:
  ```
  [[526  10]
   [ 11 307]]
  ```
- **SVC**:
  ```
  [[536   0]
   [318   0]]
  ```
- **KNN**:
  ```
  [[401 135]
   [226  92]]
  ```
- **GNB**:
  ```
  [[524  12]
   [185 133]]
  ```

### Key Insights from Results
- **Best Model**: Decision Tree achieved the highest accuracy (97.5%) with balanced precision/recall across classes, indicating strong generalization.
- **Overfitting/Underfitting**: Decision Tree shows minimal errors (only 21 misclassifications total). SVC and KNN performed poorly, likely due to lack of feature scaling (distance-based models sensitive to scale).
- **Class Imbalance Handling**: The dataset has moderate imbalance (62.7% approved, 37.3% rejected in test set). High-recall models like LDA excel on the minority class (rejected loans).
- **Warnings**: SVC had undefined precision for class 1 (no predictions for rejected loans), indicating it defaulted to predicting all as approved.

### Model Deployment
- The Decision Tree model was saved as 'decision_tree_model.joblib' using joblib for easy loading and inference in production environments.

## Discussion
### Strengths
- High accuracy from tree-based model suggests the features (especially CIBIL score, income, and assets) are strong predictors.
- Preprocessing highlighted potential data quality issues (e.g., zeros as placeholders).

### Limitations
- **Missing Code Sections**: Train-test split, LDA import, and full feature/target separation not shown; assumed based on context.
- **No Hyperparameter Tuning**: Models used defaults; grid search could improve KNN/SVC.
- **No Scaling**: SVC/KNN underperformed due to unscaled features (e.g., income in millions vs. binary education).
- **NaN Handling**: Replacing zeros with NaNs without imputation might lead to data loss; mean/median imputation or dropping NaNs recommended.
- **No Cross-Validation**: Single train-test split; k-fold CV would provide robust estimates.
- **Interpretability**: Decision Tree is interpretable (e.g., via feature importances), but not explored.

## Conclusion
The analysis demonstrates that machine learning can effectively predict loan approvals, with the Decision Tree model outperforming others at 97.5% accuracy. This model balances precision and recall, making it suitable for risk assessment where false negatives (approving bad loans) are costly.

## Recommendations
1. **Improve Preprocessing**: Apply imputation for NaNs and scale features for better performance in distance-based models.
2. **Feature Engineering**: Add ratios (e.g., loan-to-income) or encode categoricals properly if needed.
3. **Advanced Techniques**: Try ensemble methods (e.g., Random Forest) for further gains.
4. **Deployment**: Integrate the saved model into a web app (e.g., Flask) for real-time predictions.
5. **Ethical Considerations**: Ensure model fairness by checking bias in features like income or education.
6. **Future Work**: Collect more data, perform SHAP analysis for interpretability, and validate on external datasets.

**Report Generated On**: August 20, 2025  
**Author**: Grok 4 (built by xAI)
